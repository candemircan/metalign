{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using SAE Features to Generate Data\n",
        "\n",
        "SPoSE features are nice, but there is too few of them, and they are already generated from human data. An alternative approach is to take a pretrained SAE, and use the individual latent neurons of the SAE to generate classification problems. This approach not only gives you a lot more functions, but also do not directly contain human behaviour.\n",
        "\n",
        "Here, I look at some of the properties of such functions. In this case, I am using a top K sae trained on the final residual of the vision encoder of an Open CLIP model. The model is trained by ViT-Prisma, and I downloaded it from [here](https://huggingface.co/Prisma-Multimodal/sae-top_k-64-cls_only-layer_11-hook_resid_post).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from os import chdir\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "from metarep.data import h5_to_numpy, prepare_things_spose\n",
        "\n",
        "num_positive = 50\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chdir(\"..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "things_targets = h5_to_numpy(min_nonzero=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We only want to keep latents that have at least 100 non-zero values. Technically 50 would suffice, as we need 50 positive samples in the default setup, but still, it's good to be able to have some more diversity of stimuli in a given function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# give the column IDs that have at least 100 non-zero values\n",
        "nonzero_columns = np.where(np.count_nonzero(things_targets, axis=0) >= 100)[0]\n",
        "# filter the targets to only include these columns\n",
        "things_targets = things_targets[:, nonzero_columns]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I just want to see, how is difficult it is to solve these tasks using a linear classifier, compared to solving the SPoSE dimensions using the same approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.load(\"data/backbone_reps/dinov2_vitb14_reg.npz\")\n",
        "X = np.hstack([x[:] for x in X.values()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So, I train a linear classifier from the dino embeddings to every single SPoSE dimension seperately using cross-validation\n",
        "\n",
        "We assign the top `num_positive` instances from a given dimension to the positive label, and we randomly sample `num_positive` entries for the negative class from those images that have a value of 0 for this dimension. For the SPoSE classifications, no features have 0 entries. So we choose the bottom `num_positives`.\n",
        "\n",
        "\n",
        "First, the SAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline  = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(max_iter=1000, random_state=1234, n_jobs=-1)\n",
        ")\n",
        "\n",
        "data = dict(og_id=[], accuracy=[], filtered_id=[])\n",
        "for og_id, col in tqdm(zip(nonzero_columns, range(things_targets.shape[1]))):\n",
        "    # get row ids of the top num_positive activations for this column\n",
        "    top_ids = np.argsort(things_targets[:, col])[-num_positive:]\n",
        "    # get row ids of random num_positive activations that are 0 for this column\n",
        "    random_ids = np.random.choice(np.where(things_targets[:, col] == 0)[0], num_positive, replace=False)\n",
        "\n",
        "    X_sub = X[np.concatenate([top_ids, random_ids])]\n",
        "    y_sub = np.concatenate([np.ones(num_positive), np.zeros(num_positive)])\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1234)\n",
        "    cross_val_scores = cross_val_score(pipeline, X_sub, y_sub, cv=skf, scoring=\"accuracy\", n_jobs=-1)\n",
        "    accuracy = np.mean(cross_val_scores)\n",
        "    data[\"og_id\"].append(og_id)\n",
        "    data[\"accuracy\"].append(accuracy)\n",
        "    data[\"filtered_id\"].append(col)\n",
        "\n",
        "sae_df = pd.DataFrame(data)\n",
        "sae_df[\"features\"] = \"sae\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, SPoSE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, Y = prepare_things_spose(np.load(\"data/backbone_reps/dinov2_vitb14_reg.npz\"), return_tensors=\"np\")\n",
        "# do the same as above but with spose targets\n",
        "spose_data = dict(og_id=[], accuracy=[], filtered_id=[])\n",
        "for og_id in tqdm(range(Y.shape[1])):\n",
        "    # get row ids of the top num_positive activations for this column\n",
        "    top_ids = np.argsort(Y[:, og_id])[-num_positive:]\n",
        "    # get row ids of the bottom num_positive activations\n",
        "    bottom_ids = np.argsort(Y[:, og_id])[:num_positive]\n",
        "\n",
        "    X_sub = X[np.concatenate([top_ids, bottom_ids])]\n",
        "    y_sub = np.concatenate([np.ones(num_positive), np.zeros(num_positive)])\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1234)\n",
        "    cross_val_scores = cross_val_score(pipeline, X_sub, y_sub, cv=skf, scoring=\"accuracy\", n_jobs=-1)\n",
        "    accuracy = np.mean(cross_val_scores)\n",
        "    spose_data[\"og_id\"].append(og_id)\n",
        "    spose_data[\"accuracy\"].append(accuracy)\n",
        "    spose_data[\"filtered_id\"].append(og_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spose_df = pd.DataFrame(spose_data)\n",
        "spose_df[\"features\"] = \"spose\"\n",
        "df = pd.concat([sae_df, spose_df], ignore_index=True)\n",
        "\n",
        "sns.kdeplot(df, x=\"accuracy\",fill=True, hue=\"features\", common_norm=False, alpha=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The distribution of cross-validated accuracies seem similar, except a few things:\n",
        "\n",
        "- A larger part of the SAE functions are trivially solvable compared to SPoSE.\n",
        "- There are more \"medium difficulty\" functions in SPoSE compared to the SAE functions.\n",
        "- There are more \"unsolvable\" functions coming from the SAE, compared to those coming from SPoSE\n",
        "\n",
        "\n",
        "## Which categories are actually hard?\n",
        "\n",
        "Since SPoSE dimensions have labels, we can look at the accuracies per dimension with their semantic labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = open(\"data/external/labels.txt\").read().splitlines()\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sns.barplot(spose_df, x=\"og_id\", y=\"accuracy\", ax=ax)\n",
        "# rotate x tick labels by 90 degrees\n",
        "# Set the x-tick labels to the labels from the file\n",
        "ax.set_xticklabels(labels, rotation=90)\n",
        "plt.xticks(rotation=90)\n",
        "# set ylabel\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "# set xlabel\n",
        "# set ymin to 0.5\n",
        "ax.set_ylim(0.5, 1.0)\n",
        "ax.set_xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's mostly colours that seem tricky"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
