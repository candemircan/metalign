act = "gelu"
bias = true
sl = 120
logit_bias = true
compile = true
warmup_steps = 1000
training_steps = 1000000
attn_drop = 0.1
n_heads = 12
int_sz = 3072
weight_decay = 0.0001
n_layers = 2
batch_size = 4096
lr = 0.00025
use_mlp = false
